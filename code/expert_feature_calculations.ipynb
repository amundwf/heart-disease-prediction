{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.integrate import simpson\n",
    "from scipy.signal import lombscargle\n",
    "import fathon\n",
    "from fathon import fathonUtils as fu\n",
    "import nolds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected file: NSR_16272_RRI.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RR_interval_sec</th>\n",
       "      <th>sample_start</th>\n",
       "      <th>sampling_frequency</th>\n",
       "      <th>record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>73</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953125</td>\n",
       "      <td>199</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>321</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.953125</td>\n",
       "      <td>445</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.960938</td>\n",
       "      <td>567</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.976562</td>\n",
       "      <td>690</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>815</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>941</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>1065</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>1191</td>\n",
       "      <td>128</td>\n",
       "      <td>16272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RR_interval_sec  sample_start  sampling_frequency  record\n",
       "0         0.984375            73                 128   16272\n",
       "1         0.953125           199                 128   16272\n",
       "2         0.968750           321                 128   16272\n",
       "3         0.953125           445                 128   16272\n",
       "4         0.960938           567                 128   16272\n",
       "5         0.976562           690                 128   16272\n",
       "6         0.984375           815                 128   16272\n",
       "7         0.968750           941                 128   16272\n",
       "8         0.984375          1065                 128   16272\n",
       "9         0.968750          1191                 128   16272"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a selected file from one of the databases\n",
    "\n",
    "# List of databases\n",
    "databases = ['BIDMC-CHF', 'CHF-RR', 'NSR', 'NSR-RR', 'FD']\n",
    "db_name = databases[2]  # Select a database\n",
    "n = 1  # Specify which CSV file you want to read (0 for the first file)\n",
    "\n",
    "# Path to the CSV output directory\n",
    "csv_output_dir = os.path.join('../data/cleaned_RRIs/', db_name)\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(csv_output_dir):\n",
    "    # Get the list of CSV files in the directory\n",
    "    all_files = sorted(os.listdir(csv_output_dir))\n",
    "    csv_files = [f for f in all_files if f.endswith('.csv')]\n",
    "\n",
    "    # Check if there are enough CSV files in the directory to select the nth one\n",
    "    if len(csv_files) > n:\n",
    "        selected_file = csv_files[n]  # Select the nth CSV file\n",
    "        csv_file_path = os.path.join(csv_output_dir, selected_file)\n",
    "\n",
    "        # Read the selected CSV file into a DataFrame\n",
    "        df_rris = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Display the first rows of the DataFrame\n",
    "        print(f'Selected file: {selected_file}\\n')\n",
    "        display(df_rris.head(10))\n",
    "    else:\n",
    "        print(f\"Could not find file. There are fewer than {n} CSV files in the directory {csv_output_dir}.\")\n",
    "else:\n",
    "    print(f\"The directory {csv_output_dir} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for calculating features\n",
    "\n",
    "## Time domain features\n",
    "def calculate_time_domain_features(df_RRIs):\n",
    "    features = {}\n",
    "\n",
    "    RRIs = df_RRIs['RR_interval_sec']\n",
    "    RRIs = RRIs.dropna()  # This removes NaNs, if there are any (just in case)\n",
    "\n",
    "    mean_RR = RRIs.mean()\n",
    "    features['mean_RR'] = mean_RR\n",
    "    \n",
    "    std_RR = RRIs.std()\n",
    "    features['std_RR'] = std_RR\n",
    "    \n",
    "    min_RR = RRIs.min()\n",
    "    features['min_RR'] = min_RR\n",
    "    \n",
    "    features['media_RR'] = RRIs.median()\n",
    "    \n",
    "    features['CV'] = std_RR / mean_RR  # Coefficient of variation\n",
    "    \n",
    "    max_RR = RRIs.max()\n",
    "    features['delta_RRImax'] = max_RR - min_RR\n",
    "\n",
    "    # SDNN: Standard deviation of NN intervals\n",
    "    #features['SDNN'] = np.std(RRIs)\n",
    "    \n",
    "    # RMSSD: Root mean square of successive differences\n",
    "    features['RMSSD'] = np.sqrt(np.mean(np.diff(RRIs) ** 2))\n",
    "    \n",
    "    # NN50: Number of pairs of successive RR intervals that differ by more than 50 ms = 0.05 seconds\n",
    "    NN50 = np.sum(np.abs(np.diff(RRIs)) > 0.05)\n",
    "    features['NN50'] = NN50\n",
    "    \n",
    "    # pNN50: Percentage of NN50 among all of the RRIs\n",
    "    features['pNN50'] = (NN50 / len(RRIs)) * 100\n",
    "\n",
    "   # NADev: Normalized Absolute Deviation (from the mean)\n",
    "    NADev = np.mean(np.abs(RRIs - mean_RR)) / mean_RR\n",
    "    features['NADev'] = NADev\n",
    "    \n",
    "    # NADiff: Normalized Absolute Difference\n",
    "    NADiff = np.mean(np.abs(np.diff(RRIs))) / mean_RR\n",
    "    features['NADiff'] = NADiff\n",
    "\n",
    "    features_df = pd.DataFrame([features])  # Wrapping the dictionary in a list creates a single-row DataFrame\n",
    "    return features_df\n",
    "\n",
    "\n",
    "## Frequency domain features\n",
    "# Calculate vLF power, LF power, HF power and total power\n",
    "def calculate_frequency_features(df_freqs):\n",
    "    \"\"\"\n",
    "    Calculate frequency domain features from power spectral density (PSD) data.\n",
    "\n",
    "    Parameters:\n",
    "    df_freqs (DataFrame): A DataFrame containing 'Frequency (Hz)' and \n",
    "                          'Power spectral density' columns.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing total power, VLF, LF, HF power, LF/HF ratio, \n",
    "          and LF/HF power in normalized units (n.u.).\n",
    "    \"\"\"\n",
    "\n",
    "    freqs = df_freqs['Frequency (Hz)']\n",
    "    psd = df_freqs['Power spectral density']\n",
    "\n",
    "    # Define frequency bands in Hz\n",
    "    vlf_band = (0.003, 0.04)\n",
    "    lf_band = (0.04, 0.15)\n",
    "    hf_band = (0.15, 0.4)\n",
    "\n",
    "    # Separate the frequencies into the frequency bands\n",
    "    vlf_freqs = freqs[(freqs >= vlf_band[0]) & (freqs < vlf_band[1])]\n",
    "    lf_freqs = freqs[(freqs >= lf_band[0]) & (freqs < lf_band[1])]\n",
    "    hf_freqs = freqs[(freqs >= hf_band[0]) & (freqs <= hf_band[1])]\n",
    "\n",
    "    # Corresponding power spectral density values\n",
    "    vlf_psd = psd[(freqs >= vlf_band[0]) & (freqs < vlf_band[1])]\n",
    "    lf_psd = psd[(freqs >= lf_band[0]) & (freqs < lf_band[1])]\n",
    "    hf_psd = psd[(freqs >= hf_band[0]) & (freqs <= hf_band[1])]\n",
    "\n",
    "    # Calculate power in each band using numerical integration\n",
    "    vlf_power = simpson(vlf_psd, x=vlf_freqs)\n",
    "    lf_power = simpson(lf_psd, x=lf_freqs)\n",
    "    hf_power = simpson(hf_psd, x=hf_freqs)\n",
    "\n",
    "    # Calculate total power in the range 0.003 to 0.4 Hz\n",
    "    total_power = vlf_power + lf_power + hf_power\n",
    "\n",
    "    lf_hf_ratio = lf_power/hf_power\n",
    "\n",
    "    # Normalized units (percentage) for LF and HF power\n",
    "    lf_power_nu = lf_power/(total_power-vlf_power) * 100\n",
    "    hf_power_nu = hf_power/(total_power-vlf_power) * 100\n",
    "\n",
    "    frequency_features = {\n",
    "        'Total power': total_power,\n",
    "        'VLF power': vlf_power,\n",
    "        'LF power': lf_power,\n",
    "        'HF power': hf_power,\n",
    "        'LF/HF ratio': lf_hf_ratio,\n",
    "        'LF power n.u.': lf_power_nu,\n",
    "        'HF power n.u.': hf_power_nu\n",
    "    }\n",
    "    # Convert from dict to dataframe for consistency\n",
    "    df_frequency_features = pd.DataFrame(frequency_features, index=[0])\n",
    "    return df_frequency_features\n",
    "\n",
    "\n",
    "## Nonlinear features\n",
    "# Sample entropy (SampEn)\n",
    "def calculate_sample_entropy(rr_intervals):\n",
    "    # Parameters for SampEn\n",
    "    m = 2   # Embedding dimension\n",
    "    r = 0.2 * np.std(rr_intervals)  # Tolerance (20% of the standard deviation)\n",
    "    \n",
    "    # Calculate Sample Entropy\n",
    "    sample_entropy = nolds.sampen(rr_intervals, emb_dim=m, tolerance=r)\n",
    "    return sample_entropy\n",
    "\n",
    "# Poincaré plot features (SD1 and SD2):\n",
    "def calculate_SD1_SD2(rr_intervals):\n",
    "    # Calculate the differences between consecutive RR intervals\n",
    "    rr_diff = np.diff(rr_intervals)\n",
    "    \n",
    "    # Standard deviation of the RR intervals\n",
    "    SDRR = np.std(rr_intervals)\n",
    "\n",
    "    var_SD = np.var(rr_diff) # Variance of successive differences\n",
    "    # SDSD is the square root of var_SD\n",
    "    \n",
    "    # Calculate SD1 and SD2\n",
    "    SD1 = np.sqrt(var_SD / 2)  # Variability perpendicular to the line y=x (short term variation)\n",
    "    SD2 = np.sqrt(2 * SDRR**2 - SD1**2)  # Variability along the line y=x (longer term variation)\n",
    "    \n",
    "    return SD1, SD2\n",
    "\n",
    "# Renyi entropy (RyEn)\n",
    "def calculate_renyi_entropy(rr_intervals, m, alpha):\n",
    "    \"\"\"\n",
    "    Calculate Renyi entropy for RR interval data.\n",
    "\n",
    "    Parameters:\n",
    "    - rr_intervals: Array of RR intervals.\n",
    "    - m: Sequence length for embedding. \n",
    "    - alpha: Order of the Renyi entropy.\n",
    "    - (A possible value pair for m and alpha: m=8, alpha=3)\n",
    "\n",
    "    Returns:\n",
    "    - Renyi entropy value.\n",
    "    \"\"\"\n",
    "    if alpha <= 0:\n",
    "        raise ValueError(\"Alpha must be > 0\")\n",
    "    if alpha == 1:\n",
    "        raise ValueError(\"Renyi entropy undefined for alpha = 1 (use Shannon entropy instead)\")\n",
    "\n",
    "    # Embed data into m-dimensional space\n",
    "    embedded = np.array([rr_intervals[i:i + m] for i in range(len(rr_intervals) - m + 1)])\n",
    "\n",
    "    # Estimate probabilities using Gaussian kernel method\n",
    "    n = embedded.shape[0]\n",
    "    p = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        distances = np.linalg.norm(embedded - embedded[i], axis=1)\n",
    "        p[i] = np.exp(-distances).sum() - 1  # Exclude self-count\n",
    "    p /= p.sum()  # Normalize probabilities\n",
    "\n",
    "    # Calculate Renyi entropy\n",
    "    renyi_entropy = 1 / (1 - alpha) * np.log2((p ** alpha).sum())\n",
    "    return renyi_entropy\n",
    "\n",
    "# Detrended fluctuation analysis (DFA)\n",
    "def calculate_DFA(rr_intervals, min_window=5, max_window=50, step=5, pol_order=1):\n",
    "    \"\"\"\n",
    "    Calculate DFA (Detrended Fluctuation Analysis), using the Fathon library.\n",
    "\n",
    "    Parameters:\n",
    "    - rr_intervals: Array of RR intervals (1D time series)\n",
    "    - min_window: Minimum window size for DFA\n",
    "    - max_window: Maximum window size for DFA\n",
    "    - step: Step size for window sizes\n",
    "    - pol_order: Order of the polynomial for detrending\n",
    "\n",
    "    Returns:\n",
    "    - dfa_alpha: The DFA scaling exponent (Hurst exponent)\n",
    "    \"\"\"\n",
    "    # Convert RR intervals to zero-mean cumulative sum (required by fathon)\n",
    "    aggregated_rr = fu.toAggregated(rr_intervals)\n",
    "\n",
    "    # Initialize DFA object\n",
    "    pydfa = fathon.DFA(aggregated_rr)\n",
    "\n",
    "    # Define range of window sizes\n",
    "    win_sizes = fu.linRangeByStep(min_window, max_window, step)\n",
    "\n",
    "    # Compute fluctuation function\n",
    "    n, F = pydfa.computeFlucVec(win_sizes, polOrd=pol_order, revSeg=False)\n",
    "\n",
    "    # Fit fluctuation values to compute the DFA scaling exponent\n",
    "    dfa_alpha, _ = pydfa.fitFlucVec()\n",
    "    return dfa_alpha\n",
    "    \n",
    "\n",
    "def calculate_nonlinear_features(df_RRIs, test_mode=False):\n",
    "    \"\"\"\n",
    "    Calculate nonlinear features for HRV analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_RRIs: DataFrame containing a column 'RR_interval_sec' with RR intervals in seconds.\n",
    "    - test_mode: Prints computation times if True.\n",
    "\n",
    "    Returns:\n",
    "    - df_nonlinear_features: DataFrame containing nonlinear features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract RR intervals\n",
    "    rr_intervals = df_RRIs['RR_interval_sec']\n",
    "    rr_intervals = rr_intervals.dropna()  # This removes NaNs, if there are any (just in case)\n",
    "\n",
    "    # Sample entropy (SampEn)\n",
    "    start_time = time.time()\n",
    "    start_time_total = start_time\n",
    "    sampEn = calculate_sample_entropy(rr_intervals)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken for Sample Entropy calculation: {end_time - start_time:.4f} seconds\") if test_mode else None\n",
    "    \n",
    "    # Poincaré plot features (SD1 and SD2)\n",
    "    start_time = time.time()\n",
    "    SD1, SD2 = calculate_SD1_SD2(rr_intervals)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken for SD1 and SD2 calculation: {end_time - start_time:.4f} seconds\") if test_mode else None\n",
    "\n",
    "    # Renyi entropy (RyEn)\n",
    "    start_time = time.time()\n",
    "    m_ryEn = 8  # Sequence length for embedding\n",
    "    alpha_ryEn = 3  # Order of entropy\n",
    "    ryEn = calculate_renyi_entropy(rr_intervals, m_ryEn, alpha_ryEn)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken for Renyi Entropy calculation: {end_time - start_time:.4f} seconds\") if test_mode else None\n",
    "    \n",
    "    # Detrended fluctuation analysis (DFA)\n",
    "    start_time = time.time()\n",
    "    dfa_alpha = calculate_DFA(rr_intervals)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken for DFA calculation: {end_time - start_time:.4f} seconds.  DFA_alpha value: {dfa_alpha:.4f}\") if test_mode else None\n",
    "\n",
    "    end_time_total = end_time\n",
    "    print(f\"Time taken for calculation of all nonlinear features: {end_time_total - start_time_total:.4f} seconds\\n\") if test_mode else None\n",
    "\n",
    "    nonlinear_features = {\n",
    "        'SE': sampEn,\n",
    "        'SD1': SD1,\n",
    "        'SD2': SD2,\n",
    "        'RE': ryEn,\n",
    "        'DFA': dfa_alpha\n",
    "    }\n",
    "    \n",
    "    # Convert from dict to dataframe for consistency\n",
    "    df_nonlinear_features = pd.DataFrame(nonlinear_features, index=[0])\n",
    "    return df_nonlinear_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment length: N = 500\n",
      "\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf01_RRI.csv.\tNumber of segments: 149.\n",
      "Time taken to calculate features for the subject: 26.24 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf02_RRI.csv.\tNumber of segments: 181.\n",
      "Time taken to calculate features for the subject: 31.51 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf03_RRI.csv.\tNumber of segments: 156.\n",
      "Time taken to calculate features for the subject: 26.75 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf04_RRI.csv.\tNumber of segments: 221.\n",
      "Time taken to calculate features for the subject: 36.11 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf05_RRI.csv.\tNumber of segments: 236.\n",
      "Time taken to calculate features for the subject: 25.52 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf06_RRI.csv.\tNumber of segments: 223.\n",
      "Time taken to calculate features for the subject: 23.08 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf07_RRI.csv.\tNumber of segments: 180.\n",
      "Time taken to calculate features for the subject: 19.19 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf08_RRI.csv.\tNumber of segments: 179.\n",
      "Time taken to calculate features for the subject: 18.77 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf09_RRI.csv.\tNumber of segments: 228.\n",
      "Time taken to calculate features for the subject: 23.60 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf10_RRI.csv.\tNumber of segments: 293.\n",
      "Time taken to calculate features for the subject: 30.63 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf11_RRI.csv.\tNumber of segments: 230.\n",
      "Time taken to calculate features for the subject: 23.73 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf12_RRI.csv.\tNumber of segments: 230.\n",
      "Time taken to calculate features for the subject: 23.70 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf13_RRI.csv.\tNumber of segments: 230.\n",
      "Time taken to calculate features for the subject: 23.87 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf14_RRI.csv.\tNumber of segments: 186.\n",
      "Time taken to calculate features for the subject: 19.15 seconds\n",
      "\n",
      "Processing database: BIDMC-CHF, subject: BIDMC-CHF_chf15_RRI.csv.\tNumber of segments: 224.\n",
      "Time taken to calculate features for the subject: 23.57 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf201_RRI.csv.\tNumber of segments: 224.\n",
      "Time taken to calculate features for the subject: 23.26 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf202_RRI.csv.\tNumber of segments: 217.\n",
      "Time taken to calculate features for the subject: 22.28 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf203_RRI.csv.\tNumber of segments: 196.\n",
      "Time taken to calculate features for the subject: 20.40 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf204_RRI.csv.\tNumber of segments: 191.\n",
      "Time taken to calculate features for the subject: 19.59 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf205_RRI.csv.\tNumber of segments: 265.\n",
      "Time taken to calculate features for the subject: 27.16 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf206_RRI.csv.\tNumber of segments: 248.\n",
      "Time taken to calculate features for the subject: 26.16 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf207_RRI.csv.\tNumber of segments: 187.\n",
      "Time taken to calculate features for the subject: 19.23 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf208_RRI.csv.\tNumber of segments: 210.\n",
      "Time taken to calculate features for the subject: 21.40 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf209_RRI.csv.\tNumber of segments: 217.\n",
      "Time taken to calculate features for the subject: 22.80 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf210_RRI.csv.\tNumber of segments: 279.\n",
      "Time taken to calculate features for the subject: 28.55 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf211_RRI.csv.\tNumber of segments: 254.\n",
      "Time taken to calculate features for the subject: 25.80 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf212_RRI.csv.\tNumber of segments: 197.\n",
      "Time taken to calculate features for the subject: 20.69 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf213_RRI.csv.\tNumber of segments: 187.\n",
      "Time taken to calculate features for the subject: 19.33 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf214_RRI.csv.\tNumber of segments: 144.\n",
      "Time taken to calculate features for the subject: 14.72 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf215_RRI.csv.\tNumber of segments: 283.\n",
      "Time taken to calculate features for the subject: 29.67 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf216_RRI.csv.\tNumber of segments: 203.\n",
      "Time taken to calculate features for the subject: 20.56 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf217_RRI.csv.\tNumber of segments: 210.\n",
      "Time taken to calculate features for the subject: 21.19 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf218_RRI.csv.\tNumber of segments: 204.\n",
      "Time taken to calculate features for the subject: 22.32 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf219_RRI.csv.\tNumber of segments: 180.\n",
      "Time taken to calculate features for the subject: 18.31 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf220_RRI.csv.\tNumber of segments: 273.\n",
      "Time taken to calculate features for the subject: 27.48 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf221_RRI.csv.\tNumber of segments: 199.\n",
      "Time taken to calculate features for the subject: 20.85 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf222_RRI.csv.\tNumber of segments: 197.\n",
      "Time taken to calculate features for the subject: 20.50 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf223_RRI.csv.\tNumber of segments: 214.\n",
      "Time taken to calculate features for the subject: 22.09 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf224_RRI.csv.\tNumber of segments: 268.\n",
      "Time taken to calculate features for the subject: 27.81 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf225_RRI.csv.\tNumber of segments: 182.\n",
      "Time taken to calculate features for the subject: 19.16 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf226_RRI.csv.\tNumber of segments: 258.\n",
      "Time taken to calculate features for the subject: 27.92 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf227_RRI.csv.\tNumber of segments: 201.\n",
      "Time taken to calculate features for the subject: 21.80 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf228_RRI.csv.\tNumber of segments: 234.\n",
      "Time taken to calculate features for the subject: 24.12 seconds\n",
      "\n",
      "Processing database: CHF-RR, subject: CHF-RR_chf229_RRI.csv.\tNumber of segments: 245.\n",
      "Time taken to calculate features for the subject: 25.24 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_16265_RRI.csv.\tNumber of segments: 200.\n",
      "Time taken to calculate features for the subject: 20.84 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_16272_RRI.csv.\tNumber of segments: 174.\n",
      "Time taken to calculate features for the subject: 17.52 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_16273_RRI.csv.\tNumber of segments: 179.\n",
      "Time taken to calculate features for the subject: 19.15 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_16420_RRI.csv.\tNumber of segments: 204.\n",
      "Time taken to calculate features for the subject: 21.46 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_16483_RRI.csv.\tNumber of segments: 208.\n",
      "Time taken to calculate features for the subject: 20.91 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_16539_RRI.csv.\tNumber of segments: 216.\n",
      "Time taken to calculate features for the subject: 22.53 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_16773_RRI.csv.\tNumber of segments: 163.\n",
      "Time taken to calculate features for the subject: 16.95 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_16786_RRI.csv.\tNumber of segments: 203.\n",
      "Time taken to calculate features for the subject: 20.35 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_16795_RRI.csv.\tNumber of segments: 173.\n",
      "Time taken to calculate features for the subject: 18.09 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_17052_RRI.csv.\tNumber of segments: 174.\n",
      "Time taken to calculate features for the subject: 18.27 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_17453_RRI.csv.\tNumber of segments: 201.\n",
      "Time taken to calculate features for the subject: 20.78 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_18177_RRI.csv.\tNumber of segments: 231.\n",
      "Time taken to calculate features for the subject: 23.35 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_18184_RRI.csv.\tNumber of segments: 204.\n",
      "Time taken to calculate features for the subject: 22.16 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_19088_RRI.csv.\tNumber of segments: 195.\n",
      "Time taken to calculate features for the subject: 19.96 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_19090_RRI.csv.\tNumber of segments: 162.\n",
      "Time taken to calculate features for the subject: 17.06 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_19093_RRI.csv.\tNumber of segments: 150.\n",
      "Time taken to calculate features for the subject: 15.19 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_19140_RRI.csv.\tNumber of segments: 193.\n",
      "Time taken to calculate features for the subject: 20.25 seconds\n",
      "\n",
      "Processing database: NSR, subject: NSR_19830_RRI.csv.\tNumber of segments: 218.\n",
      "Time taken to calculate features for the subject: 22.52 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr001_RRI.csv.\tNumber of segments: 212.\n",
      "Time taken to calculate features for the subject: 21.34 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr002_RRI.csv.\tNumber of segments: 222.\n",
      "Time taken to calculate features for the subject: 22.88 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr003_RRI.csv.\tNumber of segments: 194.\n",
      "Time taken to calculate features for the subject: 19.37 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr004_RRI.csv.\tNumber of segments: 195.\n",
      "Time taken to calculate features for the subject: 19.52 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr005_RRI.csv.\tNumber of segments: 232.\n",
      "Time taken to calculate features for the subject: 24.45 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr006_RRI.csv.\tNumber of segments: 205.\n",
      "Time taken to calculate features for the subject: 21.25 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr007_RRI.csv.\tNumber of segments: 213.\n",
      "Time taken to calculate features for the subject: 21.36 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr008_RRI.csv.\tNumber of segments: 215.\n",
      "Time taken to calculate features for the subject: 22.07 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr009_RRI.csv.\tNumber of segments: 205.\n",
      "Time taken to calculate features for the subject: 21.41 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr010_RRI.csv.\tNumber of segments: 192.\n",
      "Time taken to calculate features for the subject: 19.29 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr011_RRI.csv.\tNumber of segments: 231.\n",
      "Time taken to calculate features for the subject: 24.41 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr012_RRI.csv.\tNumber of segments: 197.\n",
      "Time taken to calculate features for the subject: 20.09 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr013_RRI.csv.\tNumber of segments: 231.\n",
      "Time taken to calculate features for the subject: 23.82 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr014_RRI.csv.\tNumber of segments: 223.\n",
      "Time taken to calculate features for the subject: 23.05 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr015_RRI.csv.\tNumber of segments: 200.\n",
      "Time taken to calculate features for the subject: 20.11 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr016_RRI.csv.\tNumber of segments: 188.\n",
      "Time taken to calculate features for the subject: 18.68 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr017_RRI.csv.\tNumber of segments: 199.\n",
      "Time taken to calculate features for the subject: 21.33 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr018_RRI.csv.\tNumber of segments: 214.\n",
      "Time taken to calculate features for the subject: 21.54 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr019_RRI.csv.\tNumber of segments: 245.\n",
      "Time taken to calculate features for the subject: 24.56 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr020_RRI.csv.\tNumber of segments: 272.\n",
      "Time taken to calculate features for the subject: 28.57 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr021_RRI.csv.\tNumber of segments: 207.\n",
      "Time taken to calculate features for the subject: 20.75 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr022_RRI.csv.\tNumber of segments: 163.\n",
      "Time taken to calculate features for the subject: 17.00 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr023_RRI.csv.\tNumber of segments: 224.\n",
      "Time taken to calculate features for the subject: 23.11 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr024_RRI.csv.\tNumber of segments: 178.\n",
      "Time taken to calculate features for the subject: 18.52 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr025_RRI.csv.\tNumber of segments: 256.\n",
      "Time taken to calculate features for the subject: 26.07 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr026_RRI.csv.\tNumber of segments: 232.\n",
      "Time taken to calculate features for the subject: 24.15 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr027_RRI.csv.\tNumber of segments: 225.\n",
      "Time taken to calculate features for the subject: 23.24 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr028_RRI.csv.\tNumber of segments: 215.\n",
      "Time taken to calculate features for the subject: 21.86 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr029_RRI.csv.\tNumber of segments: 232.\n",
      "Time taken to calculate features for the subject: 23.82 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr030_RRI.csv.\tNumber of segments: 209.\n",
      "Time taken to calculate features for the subject: 20.78 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr031_RRI.csv.\tNumber of segments: 218.\n",
      "Time taken to calculate features for the subject: 21.76 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr032_RRI.csv.\tNumber of segments: 203.\n",
      "Time taken to calculate features for the subject: 21.60 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr033_RRI.csv.\tNumber of segments: 153.\n",
      "Time taken to calculate features for the subject: 15.27 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr034_RRI.csv.\tNumber of segments: 195.\n",
      "Time taken to calculate features for the subject: 20.25 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr035_RRI.csv.\tNumber of segments: 235.\n",
      "Time taken to calculate features for the subject: 23.97 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr036_RRI.csv.\tNumber of segments: 226.\n",
      "Time taken to calculate features for the subject: 22.54 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr037_RRI.csv.\tNumber of segments: 186.\n",
      "Time taken to calculate features for the subject: 19.55 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr038_RRI.csv.\tNumber of segments: 203.\n",
      "Time taken to calculate features for the subject: 20.83 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr039_RRI.csv.\tNumber of segments: 196.\n",
      "Time taken to calculate features for the subject: 20.44 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr040_RRI.csv.\tNumber of segments: 235.\n",
      "Time taken to calculate features for the subject: 24.28 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr041_RRI.csv.\tNumber of segments: 203.\n",
      "Time taken to calculate features for the subject: 20.60 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr042_RRI.csv.\tNumber of segments: 216.\n",
      "Time taken to calculate features for the subject: 22.02 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr043_RRI.csv.\tNumber of segments: 205.\n",
      "Time taken to calculate features for the subject: 20.37 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr044_RRI.csv.\tNumber of segments: 210.\n",
      "Time taken to calculate features for the subject: 20.96 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr045_RRI.csv.\tNumber of segments: 186.\n",
      "Time taken to calculate features for the subject: 19.99 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr046_RRI.csv.\tNumber of segments: 189.\n",
      "Time taken to calculate features for the subject: 19.01 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr047_RRI.csv.\tNumber of segments: 225.\n",
      "Time taken to calculate features for the subject: 23.34 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr048_RRI.csv.\tNumber of segments: 232.\n",
      "Time taken to calculate features for the subject: 24.39 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr049_RRI.csv.\tNumber of segments: 205.\n",
      "Time taken to calculate features for the subject: 20.66 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr050_RRI.csv.\tNumber of segments: 253.\n",
      "Time taken to calculate features for the subject: 26.39 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr051_RRI.csv.\tNumber of segments: 212.\n",
      "Time taken to calculate features for the subject: 21.37 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr052_RRI.csv.\tNumber of segments: 237.\n",
      "Time taken to calculate features for the subject: 24.56 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr053_RRI.csv.\tNumber of segments: 197.\n",
      "Time taken to calculate features for the subject: 20.48 seconds\n",
      "\n",
      "Processing database: NSR-RR, subject: NSR-RR_nsr054_RRI.csv.\tNumber of segments: 239.\n",
      "Time taken to calculate features for the subject: 24.36 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o01_RRI.csv.\tNumber of segments: 14.\n",
      "Time taken to calculate features for the subject: 1.37 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o02_RRI.csv.\tNumber of segments: 13.\n",
      "Time taken to calculate features for the subject: 1.40 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o03_RRI.csv.\tNumber of segments: 14.\n",
      "Time taken to calculate features for the subject: 1.48 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o04_RRI.csv.\tNumber of segments: 12.\n",
      "Time taken to calculate features for the subject: 1.20 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o05_RRI.csv.\tNumber of segments: 11.\n",
      "Time taken to calculate features for the subject: 1.16 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o06_RRI.csv.\tNumber of segments: 12.\n",
      "Time taken to calculate features for the subject: 1.19 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o07_RRI.csv.\tNumber of segments: 14.\n",
      "Time taken to calculate features for the subject: 1.44 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o08_RRI.csv.\tNumber of segments: 16.\n",
      "Time taken to calculate features for the subject: 1.66 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o09_RRI.csv.\tNumber of segments: 9.\n",
      "Time taken to calculate features for the subject: 1.11 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1o10_RRI.csv.\tNumber of segments: 16.\n",
      "Time taken to calculate features for the subject: 1.84 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y01_RRI.csv.\tNumber of segments: 17.\n",
      "Time taken to calculate features for the subject: 1.95 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y02_RRI.csv.\tNumber of segments: 13.\n",
      "Time taken to calculate features for the subject: 1.53 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y03_RRI.csv.\tNumber of segments: 15.\n",
      "Time taken to calculate features for the subject: 1.59 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y04_RRI.csv.\tNumber of segments: 10.\n",
      "Time taken to calculate features for the subject: 1.10 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y05_RRI.csv.\tNumber of segments: 13.\n",
      "Time taken to calculate features for the subject: 1.56 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y06_RRI.csv.\tNumber of segments: 14.\n",
      "Time taken to calculate features for the subject: 1.37 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y07_RRI.csv.\tNumber of segments: 11.\n",
      "Time taken to calculate features for the subject: 1.28 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y08_RRI.csv.\tNumber of segments: 14.\n",
      "Time taken to calculate features for the subject: 1.45 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y09_RRI.csv.\tNumber of segments: 16.\n",
      "Time taken to calculate features for the subject: 1.64 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f1y10_RRI.csv.\tNumber of segments: 17.\n",
      "Time taken to calculate features for the subject: 1.67 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o01_RRI.csv.\tNumber of segments: 14.\n",
      "Time taken to calculate features for the subject: 1.44 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o02_RRI.csv.\tNumber of segments: 12.\n",
      "Time taken to calculate features for the subject: 1.28 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o03_RRI.csv.\tNumber of segments: 12.\n",
      "Time taken to calculate features for the subject: 1.41 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o04_RRI.csv.\tNumber of segments: 13.\n",
      "Time taken to calculate features for the subject: 1.38 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o05_RRI.csv.\tNumber of segments: 16.\n",
      "Time taken to calculate features for the subject: 1.79 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o06_RRI.csv.\tNumber of segments: 10.\n",
      "Time taken to calculate features for the subject: 0.99 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o07_RRI.csv.\tNumber of segments: 11.\n",
      "Time taken to calculate features for the subject: 1.30 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o08_RRI.csv.\tNumber of segments: 12.\n",
      "Time taken to calculate features for the subject: 1.45 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o09_RRI.csv.\tNumber of segments: 12.\n",
      "Time taken to calculate features for the subject: 1.40 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2o10_RRI.csv.\tNumber of segments: 16.\n",
      "Time taken to calculate features for the subject: 1.87 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y01_RRI.csv.\tNumber of segments: 16.\n",
      "Time taken to calculate features for the subject: 1.64 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y02_RRI.csv.\tNumber of segments: 13.\n",
      "Time taken to calculate features for the subject: 1.28 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y03_RRI.csv.\tNumber of segments: 13.\n",
      "Time taken to calculate features for the subject: 1.49 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y04_RRI.csv.\tNumber of segments: 17.\n",
      "Time taken to calculate features for the subject: 1.67 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y05_RRI.csv.\tNumber of segments: 18.\n",
      "Time taken to calculate features for the subject: 1.84 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y06_RRI.csv.\tNumber of segments: 13.\n",
      "Time taken to calculate features for the subject: 1.46 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y07_RRI.csv.\tNumber of segments: 12.\n",
      "Time taken to calculate features for the subject: 1.25 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y08_RRI.csv.\tNumber of segments: 14.\n",
      "Time taken to calculate features for the subject: 1.48 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y09_RRI.csv.\tNumber of segments: 16.\n",
      "Time taken to calculate features for the subject: 1.64 seconds\n",
      "\n",
      "Processing database: FD, subject: FD_f2y10_RRI.csv.\tNumber of segments: 14.\n",
      "Time taken to calculate features for the subject: 1.45 seconds\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start_time_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 200\u001b[0m\n\u001b[0;32m    198\u001b[0m end_time_all \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Calculate and print the duration\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m duration_all \u001b[38;5;241m=\u001b[39m end_time_all \u001b[38;5;241m-\u001b[39m \u001b[43mstart_time_all\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken to calculate features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration_all\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m### Now, calculate means and standard deviations of the calculated features and save to CSV\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# read csv:\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# path_calculated_features_csv  # pd.read_csv(path_calculated_features_csv)\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Load the features CSV into a DataFrame\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start_time_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate features\n",
    "\n",
    "# Choose segment length\n",
    "N = 500\n",
    "print(f'Segment length: N = {N}\\n')\n",
    "\n",
    "# Choose which features to calculate, among time-, frequency- and nonlinear features\n",
    "#features_to_calculate = 'time' # time domain features\n",
    "#features_to_calculate = 'frequency' # frequency domain features\n",
    "features_to_calculate = 'nonlinear' # nonlinear features\n",
    "\n",
    "# Test mode = True: Run code for only two databases (one CHF, one NSR), and only 3 subjects from each of them.\n",
    "test_mode = False\n",
    "if test_mode:\n",
    "    n_subjects = 2 # Maximum number of subjects per database in test mode\n",
    "    n_segments_per_subject = 4 # Maximum number of segments analyzed per subject in test mode\n",
    "\n",
    "# Base directory where the CSV files are stored\n",
    "base_dir = '../data/cleaned_RRIs'\n",
    "\n",
    "# Directory where the calculated features CSV files are to be saved\n",
    "calculated_features_dir = '../data/calculated_features'\n",
    "os.makedirs(calculated_features_dir, exist_ok=True)\n",
    "\n",
    "# List of subdirectories representing each database\n",
    "databases = ['BIDMC-CHF', 'CHF-RR', 'NSR', 'NSR-RR', 'FD']\n",
    "databases_chf = ['BIDMC-CHF', 'CHF-RR'] # CHF = 1\n",
    "databases_nsr = ['NSR', 'NSR-RR', 'FD'] # CHF = 0\n",
    "\n",
    "if test_mode:\n",
    "    databases = [databases_chf[0], databases_nsr[0]]\n",
    "\n",
    "# Define file paths for saving calculated feature values\n",
    "if features_to_calculate == 'time':\n",
    "    # Define file name for saving calculated feature values\n",
    "    filename_calculated_features_csv = f'N{N}_time_features.csv'\n",
    "    # File names for means and standard deviations of calculated feature values\n",
    "    filename_calculated_features_means = f'N{N}_time_features_means.csv'\n",
    "    filename_calculated_features_SDs = f'N{N}_time_features_SDs.csv'\n",
    "    \n",
    "    # Define headers for the CSV file\n",
    "    headers = ['subject_id', 'database', 'CHF', 'segment_number', 'mean_RR', 'std_RR', \n",
    "                'min_RR', 'media_RR', 'CV', 'delta_RRImax', 'RMSSD', 'NN50', 'pNN50', 'NADev', 'NADiff']\n",
    "\n",
    "elif features_to_calculate == 'frequency':\n",
    "    filename_calculated_features_csv = f'N{N}_frequency_features.csv'\n",
    "    filename_calculated_features_means = f'N{N}_frequency_features_means.csv'\n",
    "    filename_calculated_features_SDs = f'N{N}_frequency_features_SDs.csv'\n",
    "\n",
    "    headers = ['subject_id', 'database', 'CHF', 'segment_number', 'Total power', 'VLF power', \n",
    "                'LF power', 'HF power', 'LF/HF ratio', 'LF power n.u.', 'HF power n.u.']\n",
    "\n",
    "elif features_to_calculate == 'nonlinear':\n",
    "    filename_calculated_features_csv = f'N{N}_nonlinear_features.csv'\n",
    "    filename_calculated_features_means = f'N{N}_nonlinear_features_means.csv'\n",
    "    filename_calculated_features_SDs = f'N{N}_nonlinear_features_SDs.csv'\n",
    "    \n",
    "    headers = ['subject_id', 'database', 'CHF', 'segment_number', 'SE', 'SD1', 'SD2', 'RE', 'DFA']\n",
    "\n",
    "# Full file path to where the calculated feature values are to be saved\n",
    "path_calculated_features_csv = os.path.join(calculated_features_dir, filename_calculated_features_csv)\n",
    "\n",
    "# Create an empty DataFrame with the relevant headers and save to CSV\n",
    "pd.DataFrame(columns=headers).to_csv(path_calculated_features_csv, index=False)\n",
    "\n",
    "# Measure the time it takes to calculate the features (all subjects)\n",
    "start_time_all = time.time()\n",
    "\n",
    "# Iterate through each database\n",
    "for db in databases:\n",
    "    db_path = os.path.join(base_dir, db)\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(db_path):\n",
    "        subjects_count = 0 if test_mode else None\n",
    "        \n",
    "        for file in os.listdir(db_path):\n",
    "            # Measure the time it takes to calculate the features of one subject\n",
    "            start_time_subj = time.time()\n",
    "            \n",
    "            if file.endswith(\".csv\"):\n",
    "                if test_mode:\n",
    "                    subjects_count += 1\n",
    "                    if subjects_count > n_subjects:\n",
    "                        break\n",
    "                    \n",
    "                # Load each CSV file\n",
    "                file_path = os.path.join(db_path, file)\n",
    "                df_rris = pd.read_csv(file_path) # RRI data of one subject\n",
    "                subject_code_name = df_rris['record'].iloc[0] # Retrieve the record (subject code name)\n",
    "                subject_code_name = str(subject_code_name) # Convert to a string to ensure it is treated as text\n",
    "                \n",
    "                # Partition the data into intervals of 500 RRIs\n",
    "                num_segments = len(df_rris) // N\n",
    "\n",
    "                # Print the database and subject file name to track progress\n",
    "                if test_mode:\n",
    "                    print(f\"\\nProcessing database: {db}, subject: {file}.\\tn_segments_per_subject (test mode): {n_segments_per_subject}.\")\n",
    "                else:\n",
    "                    print(f\"\\nProcessing database: {db}, subject: {file}.\\tNumber of segments: {num_segments}.\")\n",
    "                \n",
    "                # Process complete segments\n",
    "                for i in range(num_segments):\n",
    "                    if test_mode:\n",
    "                        #segments_count += 1\n",
    "                        if i >= n_segments_per_subject-1:\n",
    "                            break\n",
    "\n",
    "                    # Current RRI segment\n",
    "                    df_segment = df_rris.iloc[i*N:(i+1)*N]\n",
    "                    \n",
    "                    # Convert the identifying information into a DataFrame\n",
    "                    id_info = {\n",
    "                        'subject_id': subject_code_name,\n",
    "                        'database': db,\n",
    "                        'CHF': 1 if 'CHF' in db else 0,\n",
    "                        'segment_number': i + 1\n",
    "                    }\n",
    "                    df_id_info = pd.DataFrame([id_info])  # Wrap in a list to make it a single-row DataFrame\n",
    "\n",
    "                    if features_to_calculate == 'time':\n",
    "                        # Time domain features\n",
    "                        df_calculated_features = calculate_time_domain_features(df_segment)\n",
    "                        \n",
    "                    elif features_to_calculate == 'frequency':\n",
    "                        # Frequency domain features\n",
    "                        df_freqs = transform_to_frequency_domain(df_segment)\n",
    "                        df_calculated_features = calculate_frequency_features(df_freqs)\n",
    "\n",
    "                    elif features_to_calculate == 'nonlinear':\n",
    "                        df_calculated_features = calculate_nonlinear_features(df_segment, test_mode=test_mode)\n",
    "                        \n",
    "                    # Concatenate the identifying information and features\n",
    "                    combined_df = pd.concat([df_id_info, df_calculated_features], axis=1)\n",
    "\n",
    "                    # Append to CSV\n",
    "                    combined_df.to_csv(path_calculated_features_csv, mode='a', header=False, index=False)\n",
    "\n",
    "                # Handle the last segment if it's not complete\n",
    "                remaining_samples = len(df_rris) % N\n",
    "                if remaining_samples >= N // 2:\n",
    "                    # Last segment\n",
    "                    # Overlap with the previous segment to ensure we have 500 samples\n",
    "                    df_segment = df_rris.iloc[-N:]\n",
    "                    \n",
    "                    # Convert the identifying information into a DataFrame\n",
    "                    id_info = {\n",
    "                        'subject_id': subject_code_name,\n",
    "                        'database': db,\n",
    "                        'CHF': 1 if 'CHF' in db else 0,\n",
    "                        'segment_number': num_segments + 1\n",
    "                    }\n",
    "                    df_id_info = pd.DataFrame([id_info])  # Wrap in a list to make it a single-row DataFrame\n",
    "\n",
    "                    if features_to_calculate == 'time':\n",
    "                        # Time domain features\n",
    "                        df_calculated_features = calculate_time_domain_features(df_segment)\n",
    "                        \n",
    "                    elif features_to_calculate == 'frequency':\n",
    "                        # Frequency domain features\n",
    "                        df_freqs = transform_to_frequency_domain(df_rris)\n",
    "                        df_calculated_features = calculate_frequency_features(df_freqs)\n",
    "                        #print(f'type(df_freq_features): {type(df_freq_features)}')\n",
    "\n",
    "                    elif features_to_calculate == 'nonlinear':\n",
    "                        df_calculated_features = calculate_nonlinear_features(df_segment)\n",
    "\n",
    "                    # Concatenate the identifying information and features\n",
    "                    combined_df = pd.concat([df_id_info, df_calculated_features], axis=1)\n",
    "\n",
    "                    # Append to CSV\n",
    "                    combined_df.to_csv(path_calculated_features_csv, mode='a', header=False, index=False)\n",
    "            end_time_subj = time.time()\n",
    "            duration_subj = end_time_subj - start_time_subj\n",
    "            print(f\"Time taken to calculate features for the subject: {duration_subj:.2f} seconds\")\n",
    "            \n",
    "# End timing\n",
    "end_time_all = time.time()\n",
    "# Calculate and print the duration\n",
    "duration_all = end_time_all - start_time_all\n",
    "print(f\"Time taken to calculate features: {duration_all:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SE</th>\n",
       "      <th>SD1</th>\n",
       "      <th>SD2</th>\n",
       "      <th>RE</th>\n",
       "      <th>DFA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.207861</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>0.078922</td>\n",
       "      <td>8.949994</td>\n",
       "      <td>1.041602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.702377</td>\n",
       "      <td>0.079304</td>\n",
       "      <td>0.093554</td>\n",
       "      <td>8.929786</td>\n",
       "      <td>0.750057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SE       SD1       SD2        RE       DFA\n",
       "CHF                                                  \n",
       "0    1.207861  0.030471  0.078922  8.949994  1.041602\n",
       "1    0.702377  0.079304  0.093554  8.929786  0.750057"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard deviation values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SE</th>\n",
       "      <th>SD1</th>\n",
       "      <th>SD2</th>\n",
       "      <th>RE</th>\n",
       "      <th>DFA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482457</td>\n",
       "      <td>0.030608</td>\n",
       "      <td>0.043245</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.221446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545744</td>\n",
       "      <td>0.072930</td>\n",
       "      <td>0.071990</td>\n",
       "      <td>0.038129</td>\n",
       "      <td>0.282906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SE       SD1       SD2        RE       DFA\n",
       "CHF                                                  \n",
       "0    0.482457  0.030608  0.043245  0.014165  0.221446\n",
       "1    0.545744  0.072930  0.071990  0.038129  0.282906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate means and standard deviations of the calculated features and save to CSV\n",
    "\n",
    "# Load the features CSV into a DataFrame\n",
    "df_segments_features = pd.read_csv(path_calculated_features_csv)\n",
    "\n",
    "# Exclude metadata columns\n",
    "columns_to_exclude = ['subject_id', 'database', 'segment_number']\n",
    "segments_features_data = df_segments_features.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Group segments by CHF status\n",
    "segments_features_grouped_by_CHF = segments_features_data.groupby(df_segments_features['CHF'])\n",
    "\n",
    "# Get the mean values\n",
    "mean_values = segments_features_grouped_by_CHF.mean()\n",
    "\n",
    "# Get the standard deviations\n",
    "std_values = segments_features_grouped_by_CHF.std()\n",
    "\n",
    "# Drop the duplicate CHF column (keeping the grouping column, which indicates CHF = 0 or 1)\n",
    "mean_values = mean_values.drop(columns=['CHF'])\n",
    "std_values = std_values.drop(columns=['CHF'])\n",
    "\n",
    "# Save the mean and standard deviation values to separate CSV files\n",
    "path_calculated_features_means = os.path.join(calculated_features_dir, filename_calculated_features_means)\n",
    "path_calculated_features_SDs = os.path.join(calculated_features_dir, filename_calculated_features_SDs)\n",
    "mean_values.to_csv(path_calculated_features_means)\n",
    "std_values.to_csv(path_calculated_features_SDs)\n",
    "\n",
    "# Display the calculated means and standard deviations\n",
    "print(\"\\nMean values:\")\n",
    "display(mean_values)\n",
    "print(\"\\nStandard deviation values:\")\n",
    "display(std_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined mean values saved to: ../data/calculated_features\\N500_all_features_means.csv\n",
      "Combined standard deviations saved to: ../data/calculated_features\\N500_all_features_SDs.csv\n"
     ]
    }
   ],
   "source": [
    "# For the specified segment length, *combine the three CSVs* (time domain features, frequency domain features and nonlinear features)\n",
    "# into one CSV with all features (means and standard deviations of the feature values).\n",
    "\n",
    "# Segment length\n",
    "N = 500\n",
    "\n",
    "calculated_features_dir = '../data/calculated_features'  # Directory where the CSV files are stored\n",
    "\n",
    "# File paths to the CSVs with means and standard deviations of the features\n",
    "# Means\n",
    "filename_time_features_means = os.path.join(calculated_features_dir, f'N{N}_time_features_means.csv')\n",
    "filename_frequency_features_means = os.path.join(calculated_features_dir, f'N{N}_frequency_features_means.csv')\n",
    "filename_nonlinear_features_means = os.path.join(calculated_features_dir, f'N{N}_nonlinear_features_means.csv')\n",
    "# Standard Deviations\n",
    "filename_time_features_SDs = os.path.join(calculated_features_dir, f'N{N}_time_features_SDs.csv')\n",
    "filename_frequency_features_SDs = os.path.join(calculated_features_dir, f'N{N}_frequency_features_SDs.csv')\n",
    "filename_nonlinear_features_SDs = os.path.join(calculated_features_dir, f'N{N}_nonlinear_features_SDs.csv')\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "# Means\n",
    "df_time_features_means = pd.read_csv(filename_time_features_means)\n",
    "df_frequency_features_means = pd.read_csv(filename_frequency_features_means)\n",
    "df_nonlinear_features_means = pd.read_csv(filename_nonlinear_features_means)\n",
    "# Standard deviations\n",
    "df_time_features_SDs = pd.read_csv(filename_time_features_SDs)\n",
    "df_frequency_features_SDs = pd.read_csv(filename_frequency_features_SDs)\n",
    "df_nonlinear_features_SDs = pd.read_csv(filename_nonlinear_features_SDs)\n",
    "\n",
    "\n",
    "# Merge the Dataframes on 'CHF'.\n",
    "# Means\n",
    "df_all_features_means = df_time_features_means.merge(\n",
    "    df_frequency_features_means, on='CHF').merge(\n",
    "    df_nonlinear_features_means, on='CHF')\n",
    "\n",
    "# Standard deviations\n",
    "df_all_features_SDs = df_time_features_SDs.merge(\n",
    "    df_frequency_features_SDs, on='CHF').merge(\n",
    "    df_nonlinear_features_SDs, on='CHF')\n",
    "\n",
    "\n",
    "# File path for saving the combined features\n",
    "path_all_features_means = os.path.join(calculated_features_dir, f'N{N}_all_features_means.csv')\n",
    "path_all_features_SDs = os.path.join(calculated_features_dir, f'N{N}_all_features_SDs.csv')\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "df_all_features_means.to_csv(path_all_features_means, index=False)\n",
    "df_all_features_SDs.to_csv(path_all_features_SDs, index=False)\n",
    "\n",
    "print(f\"Combined mean values saved to: {path_all_features_means}\")\n",
    "print(f\"Combined standard deviations saved to: {path_all_features_SDs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary DataFrame with means ± standard deviations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV indices</th>\n",
       "      <th>NSR</th>\n",
       "      <th>CHF</th>\n",
       "      <th>p-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean_RR</td>\n",
       "      <td>0.79±0.15</td>\n",
       "      <td>0.69±0.12</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std_RR</td>\n",
       "      <td>0.06±0.04</td>\n",
       "      <td>0.09±0.07</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min_RR</td>\n",
       "      <td>0.65±0.12</td>\n",
       "      <td>0.60±0.10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media_RR</td>\n",
       "      <td>0.79±0.16</td>\n",
       "      <td>0.68±0.12</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CV</td>\n",
       "      <td>0.08±0.04</td>\n",
       "      <td>0.12±0.09</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>delta_RRImax</td>\n",
       "      <td>0.46±0.32</td>\n",
       "      <td>0.73±0.39</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RMSSD</td>\n",
       "      <td>0.04±0.04</td>\n",
       "      <td>0.11±0.10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NN50</td>\n",
       "      <td>42.96±63.47</td>\n",
       "      <td>38.99±64.77</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pNN50</td>\n",
       "      <td>8.59±12.69</td>\n",
       "      <td>7.80±12.95</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NADev</td>\n",
       "      <td>0.06±0.03</td>\n",
       "      <td>0.06±0.07</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NADiff</td>\n",
       "      <td>0.03±0.02</td>\n",
       "      <td>0.06±0.08</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total power</td>\n",
       "      <td>0.04±0.02</td>\n",
       "      <td>0.04±0.01</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VLF power</td>\n",
       "      <td>0.03±0.01</td>\n",
       "      <td>0.03±0.01</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LF power</td>\n",
       "      <td>0.00±0.01</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HF power</td>\n",
       "      <td>0.00±0.01</td>\n",
       "      <td>0.00±0.01</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LF/HF ratio</td>\n",
       "      <td>3.19±1.34</td>\n",
       "      <td>1.96±1.45</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LF power n.u.</td>\n",
       "      <td>72.62±12.49</td>\n",
       "      <td>56.81±20.95</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HF power n.u.</td>\n",
       "      <td>27.38±12.49</td>\n",
       "      <td>43.19±20.95</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SE</td>\n",
       "      <td>1.21±0.48</td>\n",
       "      <td>0.70±0.55</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SD1</td>\n",
       "      <td>0.03±0.03</td>\n",
       "      <td>0.08±0.07</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SD2</td>\n",
       "      <td>0.08±0.04</td>\n",
       "      <td>0.09±0.07</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RE</td>\n",
       "      <td>8.95±0.01</td>\n",
       "      <td>8.93±0.04</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DFA</td>\n",
       "      <td>1.04±0.22</td>\n",
       "      <td>0.75±0.28</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HRV indices          NSR          CHF p-Value\n",
       "0             CHF            0            1       -\n",
       "1         mean_RR    0.79±0.15    0.69±0.12       -\n",
       "2          std_RR    0.06±0.04    0.09±0.07       -\n",
       "3          min_RR    0.65±0.12    0.60±0.10       -\n",
       "4        media_RR    0.79±0.16    0.68±0.12       -\n",
       "5              CV    0.08±0.04    0.12±0.09       -\n",
       "6    delta_RRImax    0.46±0.32    0.73±0.39       -\n",
       "7           RMSSD    0.04±0.04    0.11±0.10       -\n",
       "8            NN50  42.96±63.47  38.99±64.77       -\n",
       "9           pNN50   8.59±12.69   7.80±12.95       -\n",
       "10          NADev    0.06±0.03    0.06±0.07       -\n",
       "11         NADiff    0.03±0.02    0.06±0.08       -\n",
       "12    Total power    0.04±0.02    0.04±0.01       -\n",
       "13      VLF power    0.03±0.01    0.03±0.01       -\n",
       "14       LF power    0.00±0.01    0.00±0.00       -\n",
       "15       HF power    0.00±0.01    0.00±0.01       -\n",
       "16    LF/HF ratio    3.19±1.34    1.96±1.45       -\n",
       "17  LF power n.u.  72.62±12.49  56.81±20.95       -\n",
       "18  HF power n.u.  27.38±12.49  43.19±20.95       -\n",
       "19             SE    1.21±0.48    0.70±0.55       -\n",
       "20            SD1    0.03±0.03    0.08±0.07       -\n",
       "21            SD2    0.08±0.04    0.09±0.07       -\n",
       "22             RE    8.95±0.01    8.93±0.04       -\n",
       "23            DFA    1.04±0.22    0.75±0.28       -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a summary DataFrame similar to Wang et al.\n",
    "\n",
    "calculated_features_dir = '../data/calculated_features'  # Directory where the CSV files are stored\n",
    "N=500\n",
    "path_all_features_means = os.path.join(calculated_features_dir, f'N{N}_all_features_means.csv')\n",
    "path_all_features_SDs = os.path.join(calculated_features_dir, f'N{N}_all_features_SDs.csv')\n",
    "\n",
    "#style = 1 # More straightforward code for presenting the results\n",
    "style = 2 # More similar to the table in Wang et al. \n",
    "\n",
    "# Import CSVs of calculated means and standard deviations\n",
    "mean_values = pd.read_csv(path_all_features_means) # e.g. ../data/calculated_features/N500_all_features_means.csv\n",
    "std_values = pd.read_csv(path_all_features_SDs)\n",
    "\n",
    "if style == 1:\n",
    "    summary_df = pd.DataFrame()\n",
    "    # Add mean and std for NSR and CHF groups\n",
    "    for column in mean_values.columns:\n",
    "        nsr_mean = mean_values.loc[0, column]\n",
    "        nsr_std = std_values.loc[0, column]\n",
    "        chf_mean = mean_values.loc[1, column]\n",
    "        chf_std = std_values.loc[1, column]\n",
    "    \n",
    "        summary_df[column] = [f\"{nsr_mean:.2f}±{nsr_std:.2f}\", f\"{chf_mean:.2f}±{chf_std:.2f}\"]\n",
    "    \n",
    "    # Set the index to specify which rows are for NSR and CHF\n",
    "    summary_df.index = ['NSR', 'CHF']\n",
    "    \n",
    "    print(\"\\nSummary DataFrame with means ± standard deviations:\")\n",
    "    display(summary_df)\n",
    "\n",
    "elif style == 2:\n",
    "    # Create lists for features, NSR, CHF, and p-value placeholders\n",
    "    hrv_indices = list(mean_values.columns)\n",
    "    nsr_values = []\n",
    "    chf_values = []\n",
    "    p_values = [\"-\" for _ in range(len(hrv_indices))]  # Placeholder for p-values, can be calculated separately\n",
    "    \n",
    "    # Populate the NSR and CHF columns with mean ± std values\n",
    "    for column in hrv_indices:\n",
    "        nsr_mean = mean_values.loc[0, column]\n",
    "        nsr_std = std_values.loc[0, column]\n",
    "        chf_mean = mean_values.loc[1, column]\n",
    "        chf_std = std_values.loc[1, column]\n",
    "\n",
    "        if column == 'CHF': # For this row in the printed table, show only 1 or 0 for simplicity.\n",
    "            nsr_values.append(f\"{nsr_mean}\")\n",
    "            chf_values.append(f\"{chf_mean}\")\n",
    "        else:\n",
    "            nsr_values.append(f\"{nsr_mean:.2f}±{nsr_std:.2f}\")\n",
    "            chf_values.append(f\"{chf_mean:.2f}±{chf_std:.2f}\")\n",
    "    \n",
    "    # Create a new DataFrame with columns similar to Wang et al. table\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"HRV indices\": hrv_indices,\n",
    "        \"NSR\": nsr_values,\n",
    "        \"CHF\": chf_values,\n",
    "        \"p-Value\": p_values  # Placeholder for now\n",
    "    })\n",
    "    \n",
    "    # Display the updated summary DataFrame\n",
    "    print(\"\\nSummary DataFrame with means ± standard deviations:\")\n",
    "    display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databases found: ['BIDMC-CHF' 'CHF-RR' 'NSR' 'NSR-RR' 'FD']\n",
      "\n",
      "Processing database: BIDMC-CHF\n",
      "  Subjects in BIDMC-CHF: ['chf01' 'chf02' 'chf03' 'chf04' 'chf05' 'chf06' 'chf07' 'chf08' 'chf09'\n",
      " 'chf10' 'chf11' 'chf12' 'chf13' 'chf14' 'chf15']\n",
      "    Processing subject: chf01\n",
      "    Processing subject: chf02\n",
      "    Processing subject: chf03\n",
      "    Processing subject: chf04\n",
      "    Processing subject: chf05\n",
      "    Processing subject: chf06\n",
      "    Processing subject: chf07\n",
      "    Processing subject: chf08\n",
      "    Processing subject: chf09\n",
      "    Processing subject: chf10\n",
      "    Processing subject: chf11\n",
      "    Processing subject: chf12\n",
      "    Processing subject: chf13\n",
      "    Processing subject: chf14\n",
      "    Processing subject: chf15\n",
      "\n",
      "Processing database: CHF-RR\n",
      "  Subjects in CHF-RR: ['chf201' 'chf202' 'chf203' 'chf204' 'chf205' 'chf206' 'chf207' 'chf208'\n",
      " 'chf209' 'chf210' 'chf211' 'chf212' 'chf213' 'chf214' 'chf215' 'chf216'\n",
      " 'chf217' 'chf218' 'chf219' 'chf220' 'chf221' 'chf222' 'chf223' 'chf224'\n",
      " 'chf225' 'chf226' 'chf227' 'chf228' 'chf229']\n",
      "    Processing subject: chf201\n",
      "    Processing subject: chf202\n",
      "    Processing subject: chf203\n",
      "    Processing subject: chf204\n",
      "    Processing subject: chf205\n",
      "    Processing subject: chf206\n",
      "    Processing subject: chf207\n",
      "    Processing subject: chf208\n",
      "    Processing subject: chf209\n",
      "    Processing subject: chf210\n",
      "    Processing subject: chf211\n",
      "    Processing subject: chf212\n",
      "    Processing subject: chf213\n",
      "    Processing subject: chf214\n",
      "    Processing subject: chf215\n",
      "    Processing subject: chf216\n",
      "    Processing subject: chf217\n",
      "    Processing subject: chf218\n",
      "    Processing subject: chf219\n",
      "    Processing subject: chf220\n",
      "    Processing subject: chf221\n",
      "    Processing subject: chf222\n",
      "    Processing subject: chf223\n",
      "    Processing subject: chf224\n",
      "    Processing subject: chf225\n",
      "    Processing subject: chf226\n",
      "    Processing subject: chf227\n",
      "    Processing subject: chf228\n",
      "    Processing subject: chf229\n",
      "\n",
      "Processing database: NSR\n",
      "  Subjects in NSR: ['16265' '16272' '16273' '16420' '16483' '16539' '16773' '16786' '16795'\n",
      " '17052' '17453' '18177' '18184' '19088' '19090' '19093' '19140' '19830']\n",
      "    Processing subject: 16265\n",
      "    Processing subject: 16272\n",
      "    Processing subject: 16273\n",
      "    Processing subject: 16420\n",
      "    Processing subject: 16483\n",
      "    Processing subject: 16539\n",
      "    Processing subject: 16773\n",
      "    Processing subject: 16786\n",
      "    Processing subject: 16795\n",
      "    Processing subject: 17052\n",
      "    Processing subject: 17453\n",
      "    Processing subject: 18177\n",
      "    Processing subject: 18184\n",
      "    Processing subject: 19088\n",
      "    Processing subject: 19090\n",
      "    Processing subject: 19093\n",
      "    Processing subject: 19140\n",
      "    Processing subject: 19830\n",
      "\n",
      "Processing database: NSR-RR\n",
      "  Subjects in NSR-RR: ['nsr001' 'nsr002' 'nsr003' 'nsr004' 'nsr005' 'nsr006' 'nsr007' 'nsr008'\n",
      " 'nsr009' 'nsr010' 'nsr011' 'nsr012' 'nsr013' 'nsr014' 'nsr015' 'nsr016'\n",
      " 'nsr017' 'nsr018' 'nsr019' 'nsr020' 'nsr021' 'nsr022' 'nsr023' 'nsr024'\n",
      " 'nsr025' 'nsr026' 'nsr027' 'nsr028' 'nsr029' 'nsr030' 'nsr031' 'nsr032'\n",
      " 'nsr033' 'nsr034' 'nsr035' 'nsr036' 'nsr037' 'nsr038' 'nsr039' 'nsr040'\n",
      " 'nsr041' 'nsr042' 'nsr043' 'nsr044' 'nsr045' 'nsr046' 'nsr047' 'nsr048'\n",
      " 'nsr049' 'nsr050' 'nsr051' 'nsr052' 'nsr053' 'nsr054']\n",
      "    Processing subject: nsr001\n",
      "    Processing subject: nsr002\n",
      "    Processing subject: nsr003\n",
      "    Processing subject: nsr004\n",
      "    Processing subject: nsr005\n",
      "    Processing subject: nsr006\n",
      "    Processing subject: nsr007\n",
      "    Processing subject: nsr008\n",
      "    Processing subject: nsr009\n",
      "    Processing subject: nsr010\n",
      "    Processing subject: nsr011\n",
      "    Processing subject: nsr012\n",
      "    Processing subject: nsr013\n",
      "    Processing subject: nsr014\n",
      "    Processing subject: nsr015\n",
      "    Processing subject: nsr016\n",
      "    Processing subject: nsr017\n",
      "    Processing subject: nsr018\n",
      "    Processing subject: nsr019\n",
      "    Processing subject: nsr020\n",
      "    Processing subject: nsr021\n",
      "    Processing subject: nsr022\n",
      "    Processing subject: nsr023\n",
      "    Processing subject: nsr024\n",
      "    Processing subject: nsr025\n",
      "    Processing subject: nsr026\n",
      "    Processing subject: nsr027\n",
      "    Processing subject: nsr028\n",
      "    Processing subject: nsr029\n",
      "    Processing subject: nsr030\n",
      "    Processing subject: nsr031\n",
      "    Processing subject: nsr032\n",
      "    Processing subject: nsr033\n",
      "    Processing subject: nsr034\n",
      "    Processing subject: nsr035\n",
      "    Processing subject: nsr036\n",
      "    Processing subject: nsr037\n",
      "    Processing subject: nsr038\n",
      "    Processing subject: nsr039\n",
      "    Processing subject: nsr040\n",
      "    Processing subject: nsr041\n",
      "    Processing subject: nsr042\n",
      "    Processing subject: nsr043\n",
      "    Processing subject: nsr044\n",
      "    Processing subject: nsr045\n",
      "    Processing subject: nsr046\n",
      "    Processing subject: nsr047\n",
      "    Processing subject: nsr048\n",
      "    Processing subject: nsr049\n",
      "    Processing subject: nsr050\n",
      "    Processing subject: nsr051\n",
      "    Processing subject: nsr052\n",
      "    Processing subject: nsr053\n",
      "    Processing subject: nsr054\n",
      "\n",
      "Processing database: FD\n",
      "  Subjects in FD: ['f1o01' 'f1o02' 'f1o03' 'f1o04' 'f1o05' 'f1o06' 'f1o07' 'f1o08' 'f1o09'\n",
      " 'f1o10' 'f1y01' 'f1y02' 'f1y03' 'f1y04' 'f1y05' 'f1y06' 'f1y07' 'f1y08'\n",
      " 'f1y09' 'f1y10' 'f2o01' 'f2o02' 'f2o03' 'f2o04' 'f2o05' 'f2o06' 'f2o07'\n",
      " 'f2o08' 'f2o09' 'f2o10' 'f2y01' 'f2y02' 'f2y03' 'f2y04' 'f2y05' 'f2y06'\n",
      " 'f2y07' 'f2y08' 'f2y09' 'f2y10']\n",
      "    Processing subject: f1o01\n",
      "    Processing subject: f1o02\n",
      "    Processing subject: f1o03\n",
      "    Processing subject: f1o04\n",
      "    Processing subject: f1o05\n",
      "    Processing subject: f1o06\n",
      "    Processing subject: f1o07\n",
      "    Processing subject: f1o08\n",
      "    Processing subject: f1o09\n",
      "    Processing subject: f1o10\n",
      "    Processing subject: f1y01\n",
      "    Processing subject: f1y02\n",
      "    Processing subject: f1y03\n",
      "    Processing subject: f1y04\n",
      "    Processing subject: f1y05\n",
      "    Processing subject: f1y06\n",
      "    Processing subject: f1y07\n",
      "    Processing subject: f1y08\n",
      "    Processing subject: f1y09\n",
      "    Processing subject: f1y10\n",
      "    Processing subject: f2o01\n",
      "    Processing subject: f2o02\n",
      "    Processing subject: f2o03\n",
      "    Processing subject: f2o04\n",
      "    Processing subject: f2o05\n",
      "    Processing subject: f2o06\n",
      "    Processing subject: f2o07\n",
      "    Processing subject: f2o08\n",
      "    Processing subject: f2o09\n",
      "    Processing subject: f2o10\n",
      "    Processing subject: f2y01\n",
      "    Processing subject: f2y02\n",
      "    Processing subject: f2y03\n",
      "    Processing subject: f2y04\n",
      "    Processing subject: f2y05\n",
      "    Processing subject: f2y06\n",
      "    Processing subject: f2y07\n",
      "    Processing subject: f2y08\n",
      "    Processing subject: f2y09\n",
      "    Processing subject: f2y10\n"
     ]
    }
   ],
   "source": [
    "# Script for copying the calculated features in \\data\\calculated_features into the \n",
    "# sub-folder \\data\\calculated_features\\N500_all_features.\n",
    "# This was added at a later stage in the project, to prepare the inputs in csvs organized by database \n",
    "# and subject (one csv for each subject), with each row in a subject's csv corresponding to one RRI segment.\n",
    "\n",
    "# Directory with previously calculated features\n",
    "features_dir_load = os.path.join(\"..\", \"data\", \"calculated_features\")\n",
    "\n",
    "# Files to combine\n",
    "feature_files = ['N500_time_features.csv', 'N500_frequency_features.csv', 'N500_nonlinear_features.csv']\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in feature_files:\n",
    "    file_path = os.path.join(features_dir_load, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "df1, df2, df3 = dfs[0], dfs[1], dfs[2]\n",
    "\n",
    "databases = df1['database'].unique() # Assuming 'database' column is consistent across all three dfs\n",
    "print(\"Databases found:\", databases)\n",
    "\n",
    "# Directory to save the updated RRI data with DL features\n",
    "features_dir_save = os.path.join(\"..\", \"data\", \"calculated_features\", \"N500_all_features\")\n",
    "\n",
    "# N500_all_features, file name example: BIDMC-CHF_chf01_RRI (f'{db}_{subject_id}_features')\n",
    "# Columns: segment_id, database, label, {feature names}\n",
    "\n",
    "for db_name in databases:\n",
    "    print(f\"\\nProcessing database: {db_name}\")\n",
    "\n",
    "    # Organize subjects by database\n",
    "    db_features_dir_save = os.path.join(features_dir_save, db_name)\n",
    "    os.makedirs(db_features_dir_save, exist_ok=True)\n",
    "\n",
    "    # Filter DataFrames for the current database\n",
    "    df1_db = df1[df1['database'] == db_name]\n",
    "    df2_db = df2[df2['database'] == db_name]\n",
    "    df3_db = df3[df3['database'] == db_name]\n",
    "\n",
    "    # Get Unique Subjects for the current database\n",
    "    subjects = df1_db['subject_id'].unique() # Assuming 'subject_id' is consistent in all dfs\n",
    "    print(f\"  Subjects in {db_name}: {subjects}\")\n",
    "\n",
    "    # Iterate through each subject in the current database\n",
    "    for subject_id in subjects:\n",
    "        print(f\"    Processing subject: {subject_id}\")\n",
    "\n",
    "        # Filter DataFrames for the current subject\n",
    "        subject_df1 = df1_db[df1_db['subject_id'] == subject_id]\n",
    "        subject_df2 = df2_db[df2_db['subject_id'] == subject_id]\n",
    "        subject_df3 = df3_db[df3_db['subject_id'] == subject_id]\n",
    "\n",
    "        # Merge the DataFrames for the current subject\n",
    "        # Use 'merge' based on the common columns. 'inner' join to keep only matching rows.\n",
    "        merged_df = pd.merge(subject_df1, subject_df2, on=['subject_id', 'database', 'CHF', 'segment_number'], how='inner')\n",
    "        merged_df = pd.merge(merged_df, subject_df3, on=['subject_id', 'database', 'CHF', 'segment_number'], how='inner')\n",
    "\n",
    "        # Rename 'CHF' to 'label'\n",
    "        merged_df = merged_df.rename(columns={'CHF': 'label'})\n",
    "        \n",
    "        # Replace the 'segment_number' column with the column 'segment_id' which will contain some more information\n",
    "        num_segments = len(merged_df)\n",
    "        merged_df['segment_number'] = merged_df['segment_number'].apply(\n",
    "            lambda segment_no: f\"{subject_id}_{str(segment_no).zfill(len(str(num_segments)))}\"\n",
    "        )\n",
    "        merged_df = merged_df.rename(columns={'segment_number': 'segment_id'})\n",
    "\n",
    "        # Drop duplicate 'segment_id's, if any\n",
    "        merged_df = merged_df.drop_duplicates(subset=['segment_id'], keep='first')\n",
    "        \n",
    "        # Save merged Dataframe to csv\n",
    "        output_file = f'{db_name}_{subject_id}_features.csv'\n",
    "        save_file_path = os.path.join(db_features_dir_save, output_file)\n",
    "        merged_df.to_csv(save_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
